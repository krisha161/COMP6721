{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from datetime import datetime\n",
    "import nltk  \n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "pd.reset_option('display.float_format')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chiragrakholiya/Downloads/Project2\n"
     ]
    }
   ],
   "source": [
    "cd /Users/chiragrakholiya/Downloads/Project2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Object ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Author</th>\n",
       "      <th>Created At</th>\n",
       "      <th>URL</th>\n",
       "      <th>Points</th>\n",
       "      <th>Number of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2294635</td>\n",
       "      <td>16043786</td>\n",
       "      <td>Top Hacker News Books in 2017</td>\n",
       "      <td>story</td>\n",
       "      <td>0x54MUR41</td>\n",
       "      <td>2018-01-01 00:06:16</td>\n",
       "      <td>https://hackernewsbooks.com/year/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2294636</td>\n",
       "      <td>16043817</td>\n",
       "      <td>Beijing enjoys best winter air quality in five...</td>\n",
       "      <td>story</td>\n",
       "      <td>gpetukhov</td>\n",
       "      <td>2018-01-01 00:15:13</td>\n",
       "      <td>http://www.scmp.com/news/china/policies-politi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2294637</td>\n",
       "      <td>16043825</td>\n",
       "      <td>Ask HN: Any domain name registrars that don't ...</td>\n",
       "      <td>ask_hn</td>\n",
       "      <td>glockenspielen</td>\n",
       "      <td>2018-01-01 00:16:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2294638</td>\n",
       "      <td>16043845</td>\n",
       "      <td>Controversial Therapy Has Led to Death Threats...</td>\n",
       "      <td>story</td>\n",
       "      <td>cpncrunch</td>\n",
       "      <td>2018-01-01 00:23:05</td>\n",
       "      <td>https://www.buzzfeed.com/tomchivers/inside-the...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2294639</td>\n",
       "      <td>16043851</td>\n",
       "      <td>Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – Wha...</td>\n",
       "      <td>story</td>\n",
       "      <td>geraldbauer</td>\n",
       "      <td>2018-01-01 00:25:05</td>\n",
       "      <td>https://planetruby.github.io/advent2017/ruby3x3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Object ID                                              Title  \\\n",
       "0     2294635   16043786                      Top Hacker News Books in 2017   \n",
       "1     2294636   16043817  Beijing enjoys best winter air quality in five...   \n",
       "2     2294637   16043825  Ask HN: Any domain name registrars that don't ...   \n",
       "3     2294638   16043845  Controversial Therapy Has Led to Death Threats...   \n",
       "4     2294639   16043851  Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – Wha...   \n",
       "\n",
       "  Post Type          Author          Created At  \\\n",
       "0     story       0x54MUR41 2018-01-01 00:06:16   \n",
       "1     story       gpetukhov 2018-01-01 00:15:13   \n",
       "2    ask_hn  glockenspielen 2018-01-01 00:16:54   \n",
       "3     story       cpncrunch 2018-01-01 00:23:05   \n",
       "4     story     geraldbauer 2018-01-01 00:25:05   \n",
       "\n",
       "                                                 URL  Points  \\\n",
       "0              https://hackernewsbooks.com/year/2017       1   \n",
       "1  http://www.scmp.com/news/china/policies-politi...       2   \n",
       "2                                                NaN       1   \n",
       "3  https://www.buzzfeed.com/tomchivers/inside-the...       2   \n",
       "4    https://planetruby.github.io/advent2017/ruby3x3       2   \n",
       "\n",
       "   Number of Comments  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 2.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data = pd.read_csv('hn2018_2019.csv', parse_dates=['Created At'], date_parser=dateparse)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Created At'][0])\n",
    "split_date=pd.datetime(2019,1,1)\n",
    "df_train = data.loc[data['Created At'] < split_date]\n",
    "df_test = data.loc[data['Created At'] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data=df_train[\"Title\"]\n",
    "Training_targets=df_train[\"Post Type\"]\n",
    "Testing_data=df_test[\"Title\"]\n",
    "Testing_targets=df_test[\"Post Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=sentence.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    sentence = sentence.lower()\n",
    "    #tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    #tk = MWETokenizer([('ask', 'hn:'), ('show', 'hn:')])\n",
    "    tokens = sentence.split()\n",
    "    tokens=[i.strip('+-:?*_,$\"\"~#%\\'\\|\\!=') for i in tokens]\n",
    "    lemma_words=[wordnet_lemmatizer.lemmatize(w) for w in tokens]\n",
    "    Filtered_word = [s for s in lemma_words if (len(s) >= 2 and len(s)<=9)]           #Filtering the words len(word)>=2 and len(word)<=9\n",
    "    return Filtered_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<276981x71051 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1963814 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(tokenizer=preprocess,stop_words=None)\n",
    "X_train_counts = count_vect.fit_transform(Training_data)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71051"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chiragrakholiya/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['tokenized_words'] = df_train['Title'].map(lambda s:preprocess(s))  #.apply(lambda row): nltk.tokenize.WhitespaceTokenizer().tokenize(row['Title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_posts=df_train['Post Type'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function preprocess at 0x1a25792050>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = list()\n",
    "for row in df_train[['Post Type', 'tokenized_words']].iterrows():\n",
    "    r = row[1]\n",
    "    for word in r.tokenized_words:\n",
    "        rows.append((r['Post Type'], word)) #wordnet_lemmatizer.lemmatize(word, pos=\"v\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Type</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>story</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>story</td>\n",
       "      <td>hacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>story</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>story</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>story</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>story</td>\n",
       "      <td>beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>story</td>\n",
       "      <td>enjoys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>story</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>story</td>\n",
       "      <td>winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>story</td>\n",
       "      <td>air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Post Type     word\n",
       "0      story      top\n",
       "1      story   hacker\n",
       "2      story     news\n",
       "3      story     book\n",
       "5      story     2017\n",
       "6      story  beijing\n",
       "7      story   enjoys\n",
       "8      story     best\n",
       "9      story   winter\n",
       "10     story      air"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = pd.DataFrame(rows, columns=['Post Type', 'word'])\n",
    "dictionary = dictionary[dictionary['word'].isin(list(count_vect.vocabulary_.keys()))]\n",
    "dictionary = dictionary[(dictionary.word.str.len() > 2 ) & (dictionary.word.str.len() <= 9)] \n",
    "dictionary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Type</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>731513</td>\n",
       "      <td>story</td>\n",
       "      <td>&amp;#43;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1193127</td>\n",
       "      <td>story</td>\n",
       "      <td>&amp;amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457115</td>\n",
       "      <td>story</td>\n",
       "      <td>&amp;amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1733552</td>\n",
       "      <td>story</td>\n",
       "      <td>&amp;amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1276861</td>\n",
       "      <td>story</td>\n",
       "      <td>&amp;amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>729741</td>\n",
       "      <td>story</td>\n",
       "      <td>{perfect}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>story</td>\n",
       "      <td>{poems}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1537942</td>\n",
       "      <td>story</td>\n",
       "      <td>{pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250580</td>\n",
       "      <td>story</td>\n",
       "      <td>{wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1042676</td>\n",
       "      <td>story</td>\n",
       "      <td>{{insert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1697239 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Post Type       word\n",
       "731513      story      &#43;\n",
       "1193127     story      &amp;\n",
       "1457115     story      &amp;\n",
       "1733552     story      &amp;\n",
       "1276861     story      &amp;\n",
       "...           ...        ...\n",
       "729741      story  {perfect}\n",
       "5650        story    {poems}\n",
       "1537942     story   {pytorch\n",
       "250580      story     {wrong\n",
       "1042676     story   {{insert\n",
       "\n",
       "[1697239 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.sort_values(by=['word'])\n",
    "#a['word'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 Unique words in our dictionary with their occurence are:\n",
      "['top', 'hacker', 'news', 'book', '2017']\n",
      "Total Unique words in our dictionary : 70161\n"
     ]
    }
   ],
   "source": [
    "Filtered_Vocab = dictionary['word'].unique().tolist()\n",
    "print(\"The top 10 Unique words in our dictionary with their occurence are:\\n{}\".format(Filtered_Vocab[0:5]))\n",
    "Filtered_Vocab.sort()\n",
    "print(\"Total Unique words in our dictionary :\",len(Filtered_Vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': 1540249, 'ask_hn': 88663, 'show_hn': 68156, 'poll': 171}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_words_each_cat={}\n",
    "for i in range(len(Unique_posts)):\n",
    "    Total_words_each_cat[Unique_posts[i]]=len(dictionary.loc[dictionary['Post Type']== '{}'.format(Unique_posts[i])])\n",
    "\n",
    "Total_words_each_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': 66598, 'ask_hn': 7456, 'show_hn': 9578, 'poll': 94}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unique_words_each_cat={}\n",
    "for i in range(len(Unique_posts)):\n",
    "    Unique_words_each_cat[Unique_posts[i]]=len(dictionary.loc[dictionary['Post Type']=='{}'.format(Unique_posts[i])]['word'].unique())\n",
    "\n",
    "Unique_words_each_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def apperance_in_catergory_story(vocab):\n",
    "#    Count_list=[]\n",
    "#    for post in range(len(Unique_posts)):\n",
    "#        try:\n",
    "#            Count_list.append(dictionary.loc[dictionary['word']=='{}'.format(vocab)].groupby(['Post Type']).get_group('{}'.format(Unique_posts[post])).word.value_counts().to_frame().rename(columns={'word':'num_of_times'})['num_of_times'][0])\n",
    "#        except KeyError:\n",
    "#            Count_list.append(0)\n",
    "#   \n",
    "#    return Count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-758e2409b5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnique_posts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mCount_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFiltered_Vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Post Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnique_posts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'num_of_times'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_of_times'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mCount_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 raise TypeError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myfile = open('wordlength-model.txt', 'w',buffering=4096)\n",
    "#myfile.write(\"Counter  Word  Freq_in_Story  Cond_prob_sty  Fq_in_ah  Cond_pr_ah  Fq_in_show_hn  Cond_prob_sh  Freq_in_poll  Cond_prob_poll\\n\")\n",
    "for word in range(len(Filtered_Vocab)):\n",
    "    Count_list=[]\n",
    "    for post in range(len(Unique_posts)):\n",
    "        try:\n",
    "            Count_list.append(dictionary.loc[dictionary['word']=='{}'.format(Filtered_Vocab[word])].groupby(['Post Type']).get_group('{}'.format(Unique_posts[post])).word.value_counts().to_frame().rename(columns={'word':'num_of_times'})['num_of_times'][0])\n",
    "        except KeyError:\n",
    "            Count_list.append(0)\n",
    "        \n",
    "    myfile.write(\"{}  {}  {} {}  {}  {}  {}  {}  {}  {}\\n\".format(word+1,Filtered_Vocab[word],Count_list[0],format((Count_list[0]+0.5)/(Total_words_each_cat['story']+Unique_words_each_cat['story']),'.8f'),Count_list[1],format((Count_list[1]+0.5)/(Total_words_each_cat['ask_hn']+Unique_words_each_cat['ask_hn']),'.8f'),Count_list[2],format((Count_list[2]+0.5)/(Total_words_each_cat['show_hn']+Unique_words_each_cat['show_hn']),'.8f'),Count_list[3],format((Count_list[3]+0.5)/(Total_words_each_cat['poll']+Unique_words_each_cat['poll']),'.8f')))\n",
    "\n",
    "myfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "#X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "#X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276981, 71051)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.5, fit_prior=True, class_prior=None).fit(X_train_tfidf,Training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_counts = count_vect.transform(Testing_data)\n",
    "Testing_tfidf = tfidf_transformer.transform(Testing_counts)\n",
    "\n",
    "predicted = clf.predict_proba(Testing_tfidf)\n",
    "predicted_string = clf.predict(Testing_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('wordlength-result.txt', 'w',buffering=4096)\n",
    "for doc, pred_class, category , actual in zip(Testing_data.tolist(),predicted_string, predicted ,Testing_targets):\n",
    "     myfile.write('%r  %s  %f  %f  %f  %f  %s %s' % (doc, pred_class ,category[3] ,category[0],category[2],category[1],actual,'right\\n' if pred_class == actual else 'wrong\\n'))\n",
    "myfile.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451590569544146"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted_string == Testing_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
