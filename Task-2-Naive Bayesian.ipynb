{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "pd.reset_option('display.float_format')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "pd.reset_option('display.float_format')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chiragrakholiya/Downloads/Project2\n"
     ]
    }
   ],
   "source": [
    "cd /Users/chiragrakholiya/Downloads/Project2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Object ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Author</th>\n",
       "      <th>Created At</th>\n",
       "      <th>URL</th>\n",
       "      <th>Points</th>\n",
       "      <th>Number of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2294635</td>\n",
       "      <td>16043786</td>\n",
       "      <td>Top Hacker News Books in 2017</td>\n",
       "      <td>story</td>\n",
       "      <td>0x54MUR41</td>\n",
       "      <td>2018-01-01 00:06:16</td>\n",
       "      <td>https://hackernewsbooks.com/year/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2294636</td>\n",
       "      <td>16043817</td>\n",
       "      <td>Beijing enjoys best winter air quality in five...</td>\n",
       "      <td>story</td>\n",
       "      <td>gpetukhov</td>\n",
       "      <td>2018-01-01 00:15:13</td>\n",
       "      <td>http://www.scmp.com/news/china/policies-politi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2294637</td>\n",
       "      <td>16043825</td>\n",
       "      <td>Ask HN: Any domain name registrars that don't ...</td>\n",
       "      <td>ask_hn</td>\n",
       "      <td>glockenspielen</td>\n",
       "      <td>2018-01-01 00:16:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2294638</td>\n",
       "      <td>16043845</td>\n",
       "      <td>Controversial Therapy Has Led to Death Threats...</td>\n",
       "      <td>story</td>\n",
       "      <td>cpncrunch</td>\n",
       "      <td>2018-01-01 00:23:05</td>\n",
       "      <td>https://www.buzzfeed.com/tomchivers/inside-the...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2294639</td>\n",
       "      <td>16043851</td>\n",
       "      <td>Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – Wha...</td>\n",
       "      <td>story</td>\n",
       "      <td>geraldbauer</td>\n",
       "      <td>2018-01-01 00:25:05</td>\n",
       "      <td>https://planetruby.github.io/advent2017/ruby3x3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Object ID                                              Title  \\\n",
       "0     2294635   16043786                      Top Hacker News Books in 2017   \n",
       "1     2294636   16043817  Beijing enjoys best winter air quality in five...   \n",
       "2     2294637   16043825  Ask HN: Any domain name registrars that don't ...   \n",
       "3     2294638   16043845  Controversial Therapy Has Led to Death Threats...   \n",
       "4     2294639   16043851  Ruby 3x3 – Ruby 3 Will Be 3 Times Faster – Wha...   \n",
       "\n",
       "  Post Type          Author          Created At  \\\n",
       "0     story       0x54MUR41 2018-01-01 00:06:16   \n",
       "1     story       gpetukhov 2018-01-01 00:15:13   \n",
       "2    ask_hn  glockenspielen 2018-01-01 00:16:54   \n",
       "3     story       cpncrunch 2018-01-01 00:23:05   \n",
       "4     story     geraldbauer 2018-01-01 00:25:05   \n",
       "\n",
       "                                                 URL  Points  \\\n",
       "0              https://hackernewsbooks.com/year/2017       1   \n",
       "1  http://www.scmp.com/news/china/policies-politi...       2   \n",
       "2                                                NaN       1   \n",
       "3  https://www.buzzfeed.com/tomchivers/inside-the...       2   \n",
       "4    https://planetruby.github.io/advent2017/ruby3x3       2   \n",
       "\n",
       "   Number of Comments  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 2.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data = pd.read_csv('hn2018_2019.csv', parse_dates=['Created At'], date_parser=dateparse)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Factorizing Our Target Class to Manage the Computation Power</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Postype_id'] = data[\"Post Type\"].factorize()[0]\n",
    "#category_id_df = data[[\"Post Type\", 'Postype_id']].drop_duplicates().sort_values('Postype_id')\n",
    "#category_to_id = dict(category_id_df.values)\n",
    "#id_to_category = dict(category_id_df[['Postype_id', \"Post Type\"]].values)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category_to_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4dbfb43ee87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategory_to_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'category_to_id' is not defined"
     ]
    }
   ],
   "source": [
    "category_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Dividing into test and training class</H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['Created At'][0])\n",
    "split_date=pd.datetime(2019,1,1)\n",
    "df_train = data.loc[data['Created At'] < split_date]\n",
    "df_test = data.loc[data['Created At'] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data=df_train[\"Title\"]\n",
    "Training_targets=df_train[\"Post Type\"]\n",
    "Testing_data=df_test[\"Title\"]\n",
    "Testing_targets=df_test[\"Post Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=sentence.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    sentence = sentence.lower()\n",
    "    #tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    #tk = MWETokenizer([('ask', 'hn:'), ('show', 'hn:')])\n",
    "    tokens = sentence.split()\n",
    "    tokens=[i.strip('+-:?*_,~\\'') for i in tokens]\n",
    "    lemma_words=[wordnet_lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<276981x106423 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2219598 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(tokenizer=preprocess,stop_words=None)\n",
    "X_train_counts = count_vect.fit_transform(Training_data)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<276981x106423 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2219598 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276981, 106423)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=0.5, fit_prior=True, class_prior=None).fit(X_train_tfidf,Training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show_hn']\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(count_vect.transform([\"Show HN Just Read – The best reader mode for Chrome\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_counts = count_vect.transform(Testing_data)\n",
    "Testing_tfidf = tfidf_transformer.transform(Testing_counts)\n",
    "\n",
    "predicted = clf.predict_proba(Testing_tfidf)\n",
    "predicted_string = clf.predict(Testing_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('baseline-results.txt', 'w',buffering=4096)\n",
    "for doc, pred_class, category , actual in zip(Testing_data.tolist(),predicted_string, predicted ,Testing_targets):\n",
    "     myfile.write('%r  %s  %f  %f  %f  %f  %s %s' % (doc, pred_class ,category[3] ,category[0],category[2],category[1],actual,'right\\n' if pred_class == actual else 'wrong\\n'))\n",
    "myfile.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343147615056663"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted_string == Testing_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
